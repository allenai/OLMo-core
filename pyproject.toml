[build-system]
requires = ["setuptools", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "ai2-olmo-core"
dynamic = ["version"]
readme = "README.md"
description = "Core training module for the Open Language Model (OLMo)"
authors = [
    { name = "Allen Institute for Artificial Intelligence", email = "olmo@allenai.org" },
]
requires-python = ">=3.10"
license = { file = "LICENSE" }
dependencies = [
    "numpy",
    "torch>=2.6.0",
    "cached-path>=1.7.2",
    "requests",
    "packaging",
    "rich",
    "omegaconf",
    "safetensors",
    "importlib_resources",
    "bettermap",
    "pandas",
]

[project.urls]
Homepage = "https://github.com/allenai/OLMo-core"
Documentation = "https://olmo-core.readthedocs.io/en/latest/"
Changelog = "https://github.com/allenai/OLMo-core/blob/main/CHANGELOG.md"

[project.optional-dependencies]
dev = [
    "black>=23.1,<24.0",
    "boto3",
    "build",
    "furo==2024.8.6",
    "google-cloud-storage",
    "isort>=5.12,<5.14",
    "matplotlib",
    "mypy>=1.0,<1.4",
    "myst-parser>=1.0,<3.0",
    "pytest",
    "pytest-memray",
    "pytest-sphinx",
    "pytest-xdist",
    "ruff",
    "setuptools",
    "Sphinx>=6.0,<=8.1.3",
    "sphinx-autobuild",
    "sphinx-autodoc-typehints==1.23.3",
    "sphinx-copybutton",
    "sphinx-inline-tabs",
    "twine>=1.11.0",
    "wheel",
]
beaker = ["beaker-py>=2.5.4,<3.0", "beaker-gantry>=3.4.3,<4.0", "GitPython>=3.0,<4.0", "google-cloud-compute"]
comet = ["comet_ml"]
dion = ["dion @ git+https://github.com/microsoft/dion.git@7452a5823cf9655b93c3f1d8020b4ebb2535239b ; sys_platform == 'linux'"]
eval = ["ai2-olmo-eval==0.8.5"]
torchao = ["torchao==0.15.0"]
transformers = ["transformers"]
wandb = ["wandb"]
gpu = [
    "flash-attn>=2.8.2; platform_system != 'Darwin'",
    "flash-attn-3; platform_system != 'Darwin'",
    "grouped-gemm; platform_system != 'Darwin'",
    "transformer-engine[pytorch]>=2.9; platform_system != 'Darwin'",
    "ring-flash-attn>=0.1.8; platform_system != 'Darwin'",
    "liger-kernel>=0.6.4; platform_system != 'Darwin'",
]
all = ["ai2-olmo-core[dev,beaker,comet,dion,eval,torchao,transformers,wandb,gpu]"]


[tool.setuptools]
include-package-data = true

[tool.setuptools.package-data]
olmo_core = ["py.typed", "*.txt"]

[tool.setuptools.dynamic]
version = { attr = "olmo_core.version.VERSION" }

[tool.setuptools.packages.find]
where = ["src"]
include = ["olmo_core*"]
exclude = []

[tool.black]
line-length = 100
include = '\.pyi?$'
exclude = '''
(
      __pycache__
    | \.git
    | \.mypy_cache
    | \.pytest_cache
    | \.vscode
    | \.venv
    | \bdist\b
    | \bdoc\b
    | scratch/
)
'''

[tool.isort]
profile = "black"
multi_line_output = 3

[tool.ruff]
line-length = 100

[tool.ruff.lint]
ignore = ["F403", "F405", "E501"]
exclude = [
    ".bzr",
    ".direnv",
    ".eggs",
    ".git",
    ".venv",
    "venv",
    ".mypy_cache",
    "__pycache__",
    ".nox",
    ".pants.d",
    ".pytype",
    ".ruff_cache",
    ".svn",
    ".tox",
    "__pypackages__",
    "_build",
    "buck-out",
    "build",
    "dist",
    "node_modules",
    "doc",
    "pretrain_data",
    "inference",
]

[tool.ruff.lint.per-file-ignores]
"**/__init__.py" = ["F401"]

[tool.pyright]
reportPrivateImportUsage = false

[tool.ty.rules]
possibly-missing-attribute = "ignore"
possibly-missing-import = "ignore"
unresolved-attribute = "warn"

[[tool.ty.overrides]]
include = ["src/olmo_core/nn/**"]

[tool.ty.overrides.rules]
unresolved-attribute = "ignore"

[tool.mypy]
ignore_missing_imports = true
no_site_packages = true
check_untyped_defs = true
namespace_packages = false
disable_error_code = "has-type"

[[tool.mypy.overrides]]
module = "tests.*"
strict_optional = false

[tool.uv]
environments = [
    "sys_platform == 'darwin'",
    "sys_platform == 'linux'",
]

[tool.uv.extra-build-dependencies]
flash-attn = [{ requirement = "torch", match-runtime = true }]
flash-attn-3 = [{ requirement = "torch", match-runtime = true }, "packaging", "wheel"]
grouped-gemm = [{ requirement = "torch", match-runtime = true }]
transformer-engine = [{ requirement = "torch", match-runtime = true }]
ring-flash-attn = [{ requirement = "torch", match-runtime = true }]
liger-kernel = [{ requirement = "torch", match-runtime = true }]

[tool.uv.extra-build-variables]
flash-attn = { FLASH_ATTENTION_SKIP_CUDA_BUILD = "TRUE" }
flash-attn-3 = { FLASH_ATTENTION_SKIP_CUDA_BUILD = "TRUE" }
grouped-gemm = { GROUPED_GEMM_CUTLASS = "1" }

[tool.uv.sources]
torch = [{ index = "pytorch-cu128", marker = "platform_system != 'Darwin'" }]
grouped-gemm = { git = "https://github.com/tgale96/grouped_gemm.git", branch = "main" }
flash-attn-3 = { git = "https://github.com/Dao-AILab/flash-attention.git", subdirectory = "hopper" }

[[tool.uv.index]]
name = "pytorch-cu128"
url = "https://download.pytorch.org/whl/cu128"
explicit = true

[tool.pytest.ini_options]
testpaths = "src/test/"
python_classes = ["Test*", "*Test"]
log_format = "%(asctime)s - %(levelname)s - %(name)s - %(message)s"
log_level = "DEBUG"
log_cli = false
log_cli_level = "DEBUG"
markers = ["gpu"]
filterwarnings = [
    'ignore::FutureWarning:huggingface_hub\.file_download',
    'ignore::DeprecationWarning:pkg_resources',
    'ignore::DeprecationWarning:google\.rpc',
    'ignore::DeprecationWarning:torchao\.dtypes.*',
    'ignore::FutureWarning:torch\.distributed\.checkpoint\.default_planner',
    'ignore::UserWarning:torch\.distributed\.checkpoint\.state_dict_saver',
    'ignore::UserWarning:torch\.distributed\.checkpoint\.state_dict_loader',
]
