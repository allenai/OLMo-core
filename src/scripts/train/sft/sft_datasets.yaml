datasets:
  allenai/tulu-3-sft-olmo-2-mixture:
    # https://huggingface.co/datasets/allenai/tulu-3-sft-olmo-2-mixture
    base_dir: jacobm/data/sft/jacobmorrison/tulu-3-sft-olmo-2-mixture
    # NOTE: be careful that this tokenizer matches the pretraining data you've prepared!
    # https://huggingface.co/allenai/OLMo-2-1124-7B-Instruct
    tokenizer: allenai/OLMo-2-1124-7B-Instruct
    token_ids:
      - token_ids_part_0000.npy
      - token_ids_part_0001.npy
      - token_ids_part_0002.npy
    labels:
      - labels_part_0000.npy
      - labels_part_0001.npy
      - labels_part_0002.npy

  OpenThoughts3-1.2M-no-cot:
    # Openthoughts3-1.2M dataset without COT
    base_dir: tylerr/data/sft/jacobmorrison-OpenThoughts3-1.2M-no-cot
    tokenizer: allenai/OLMo-2-1124-7B-Instruct
    token_ids:
      - token_ids_part_0000.npy
      - token_ids_part_0001.npy
    labels:
      - labels_part_0000.npy
      - labels_part_0001.npy

  OpenThoughts3-1.2M:
    # Openthoughts3-1.2M dataset with COT
    base_dir: tylerr/data/sft/jacobmorrison-OpenThoughts3-1.2M
    tokenizer: allenai/OLMo-2-1124-7B-Instruct
    token_ids:
      - token_ids_part_0000.npy
      - token_ids_part_0001.npy
    labels:
      - labels_part_0000.npy
      - labels_part_0001.npy
